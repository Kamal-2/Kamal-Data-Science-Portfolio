# Kamal Douglas: Data Science Portfolio

A collection of personal projects demonstrating technical proficiency in Python (Pandas, Scikit-learn), SQL, and Data Visualization (Excel/Tableau/Power BI) for solving real-world business and operational challenges.

## Key Skills Demonstrated:**

**Python for Automation & Analysis** | Using Pandas, Numpy, and core python to clean, transform, aggregate, and automate repetitive data tasks, mirroring process optimization efforts in banking operations. | *Data_Wranglining_Script, Operational_Efficiency_Automator*

**Machine Learning & Modeling** | Applying Scikit - learn to build predictive models (classification/regression) and demonstrating the ability to evaluate model performance and derive actionable insights | *Churn_Predition_Model, Loan_Risk_Assessment*

**SQL Database Proficiency** | Demonstrating capability in designing relational schemas, writing complex queries (joins, window functions) and performing data extraction, validation, and manipulation. | *Database_Design_Project, Complex_SQL_Queries*

**Data Storytelling** | Providing clear,well-documented project notebooks that translate technical results and statistical findings into plain English business outcomes.| *All projects feature detailed analysis and conclusion summaries*

**Tools & Platforms** | Experience with **Git** for version control, and conceptual knowledge of large data environments like **Azure** and **Databricks** | *This README, all code files and commit history.*

## Featured Projects

Here are three high-impact project ideas that directly address my revlevant skills:

**1. Operational Efficiency Automation Script (Operational_Efficiency_Automator)**

- Goal: Simulate automating a manual, time-consuming reporting or data reconciliation task common in banking operations.
- Technologies: Python (Pandas, native file handling), mock data generation.
- Data Storytelling: Quantify the time/error reduction achieved by the automation script.
- Mapping to TD Role: Shows direct capability in process optimization and driving operational efficiency using Python.
  
__2. Loan Risk Classification Model (Loan_Risk_Assessment)__

- Goal: Build a predictive model to classify potential loan applicants based on risk using a synthetic financial dataset.
- Technologies: Python (Pandas, NumPy, Scikit-learn - e.g., Logistic Regression or Random Forest), Jupyter Notebook.
- Data Storytelling: Discuss feature importance and how the model's output informs strategic planning (which is a key function of the A12 team).
- Mapping to TD Role: Directly demonstrates proficiency with Scikit-learn and statistical modeling for financial decision support.
  
__3. SQL Data Validation and ETL Simulation (Database_Design_Project)__

- Goal: Create a clean database schema and a series of SQL queries designed to validate data integrity and extract aggregated metrics.
- Technologies: SQL (T-SQL, PostgreSQL, or SQLite), detailed query files.
- Data Storytelling: Explain the process of ensuring data accuracy for downstream reporting (linking back to your current experience validating dashboard data).
- Mapping to TD Role: Validates your project-based proficiency in SQL for complex querying and data preparation.

Thank you for reviewing my portfolio. I look forward to discussing how these skills can drive analytical insights for the CPB Operations team.
